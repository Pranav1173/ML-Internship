{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7052a6de-29af-467e-b9e0-2b1d6563e062",
   "metadata": {},
   "source": [
    "# Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77c9bc6-c57c-4756-a780-52d46118f4a5",
   "metadata": {},
   "source": [
    "*The FER2013 dataset used, is a popular facial expression recognition dataset used for training and evaluating emotion recognition models.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92316755-24df-4150-bed5-733068cff823",
   "metadata": {},
   "source": [
    "*Link for the dataset* : **https://www.kaggle.com/datasets/msambare/fer2013/**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15fb90a-24c4-4216-b99d-50c353247194",
   "metadata": {},
   "source": [
    "# Detection Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ad3f7d-c105-47b3-8a54-17553b905659",
   "metadata": {},
   "source": [
    "*Importing the required dependencies*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba412e87-67ae-4e88-8507-7b4cb85c1ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84c663c5-9f07-4336-986a-5db136616fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'train/'\n",
    "test_dir = 'test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a6d631-315f-422b-a734-2f48d0ab7e48",
   "metadata": {},
   "source": [
    "*Defining Function to create data frames for both train and test directory*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2d425fa-8b87-4338-bfef-4d84e089b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdf(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir, label)):\n",
    "            image_paths.append(os.path.join(dir, label, imagename))\n",
    "            labels.append(label)\n",
    "        print(label, \"Labelled\")\n",
    "    return image_paths, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8214643-2597-444f-9bd6-a574d7054494",
   "metadata": {},
   "source": [
    "*Labelling the datasets - test and train*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aa0f0dc-1cc6-435d-8957-f664ce58d5f3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry Labelled\n",
      "disgust Labelled\n",
      "fear Labelled\n",
      "happy Labelled\n",
      "neutral Labelled\n",
      "sad Labelled\n",
      "surprise Labelled\n",
      "angry Labelled\n",
      "disgust Labelled\n",
      "fear Labelled\n",
      "happy Labelled\n",
      "neutral Labelled\n",
      "sad Labelled\n",
      "surprise Labelled\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "train['image'], train['label'] = createdf(train_dir)\n",
    "\n",
    "test = pd.DataFrame()\n",
    "test['image'], test['label'] = createdf(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fba5acd3-7477-4c69-8a75-ab457f12f2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_ext(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image, color_mode='grayscale', target_size=(48, 48))\n",
    "        img = img_to_array(img) / 255.0\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "250ce2b2-e143-49f1-91a0-9b5e2ec1e3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f634542a02f94447881c7ee731c23f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28709 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d1543950756412db985785f35f324ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_feats = feat_ext(train['image'])\n",
    "test_feats = feat_ext(test['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4a9bdc-a1cc-4a11-b7ee-507dd81cf0ff",
   "metadata": {},
   "source": [
    "*Using Label Encoder - To convert a class vector (integers) to binary class matrix.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17798ebd-8983-4dad-a9ee-32ecbd27dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbed = LabelEncoder()\n",
    "lbed.fit(train['label'])\n",
    "y_train = to_categorical(lbed.transform(train['label']), num_classes=7)\n",
    "y_test = to_categorical(lbed.transform(test['label']), num_classes=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799166f0-a2e9-445d-9fd4-282e8ddd22e2",
   "metadata": {},
   "source": [
    "*Defining the Model Layers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faa894d6-2fdc-447a-bd84-6721ff1e31ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7974c4eb-2845-4c3b-92e7-fc39d7d62697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 2.1298 - accuracy: 0.2124"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1110s 5s/step - loss: 2.1298 - accuracy: 0.2124 - val_loss: 1.9109 - val_accuracy: 0.2471 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 958s 4s/step - loss: 1.7204 - accuracy: 0.3307 - val_loss: 2.2527 - val_accuracy: 0.2487 - lr: 9.0000e-04\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 877s 4s/step - loss: 1.5015 - accuracy: 0.4198 - val_loss: 1.9542 - val_accuracy: 0.3402 - lr: 8.1000e-04\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 848s 4s/step - loss: 1.3672 - accuracy: 0.4745 - val_loss: 1.3024 - val_accuracy: 0.4979 - lr: 7.2900e-04\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 852s 4s/step - loss: 1.2800 - accuracy: 0.5127 - val_loss: 1.2740 - val_accuracy: 0.5100 - lr: 6.5610e-04\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 849s 4s/step - loss: 1.2156 - accuracy: 0.5351 - val_loss: 1.2724 - val_accuracy: 0.5110 - lr: 5.9049e-04\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 852s 4s/step - loss: 1.1674 - accuracy: 0.5554 - val_loss: 1.1839 - val_accuracy: 0.5507 - lr: 5.3144e-04\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 900s 4s/step - loss: 1.1275 - accuracy: 0.5721 - val_loss: 1.2729 - val_accuracy: 0.5291 - lr: 4.7830e-04\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 891s 4s/step - loss: 1.0809 - accuracy: 0.5912 - val_loss: 1.1043 - val_accuracy: 0.5840 - lr: 4.3047e-04\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 891s 4s/step - loss: 1.0479 - accuracy: 0.6036 - val_loss: 1.0760 - val_accuracy: 0.5971 - lr: 3.8742e-04\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 886s 4s/step - loss: 1.0117 - accuracy: 0.6194 - val_loss: 1.1153 - val_accuracy: 0.5843 - lr: 3.4868e-04\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 890s 4s/step - loss: 0.9686 - accuracy: 0.6364 - val_loss: 1.0602 - val_accuracy: 0.6101 - lr: 3.1381e-04\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 887s 4s/step - loss: 0.9452 - accuracy: 0.6420 - val_loss: 1.0578 - val_accuracy: 0.6081 - lr: 2.8243e-04\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 867s 4s/step - loss: 0.9177 - accuracy: 0.6539 - val_loss: 1.0239 - val_accuracy: 0.6226 - lr: 2.5419e-04\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 850s 4s/step - loss: 0.8760 - accuracy: 0.6731 - val_loss: 1.0124 - val_accuracy: 0.6276 - lr: 2.2877e-04\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 854s 4s/step - loss: 0.8541 - accuracy: 0.6810 - val_loss: 1.0874 - val_accuracy: 0.6076 - lr: 2.0589e-04\n",
      "Epoch 17/100\n",
      "214/225 [===========================>..] - ETA: 39s - loss: 0.8261 - accuracy: 0.6893"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Defining callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('model_weights.h5', save_best_only=True)\n",
    "learning_rate_scheduler = LearningRateScheduler(lambda epoch: 0.001 * 0.9 ** epoch)\n",
    "\n",
    "# Training the model\n",
    "model.fit(x=train_feats, y=y_train, batch_size=128, epochs=100, validation_data=(test_feats, y_test), callbacks=[early_stop, model_checkpoint, learning_rate_scheduler])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af699aa6-338d-4203-939c-06a31d1f0551",
   "metadata": {},
   "source": [
    "***Interrupted the execution because too many epochs. 15-20 Epochs are more than enough. Keep Patience in range of 2-4***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03e75a48-3119-42c6-a2bc-01efebb8af57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model architecture to a JSON file\n",
    "model_json = model.to_json()\n",
    "with open(\"model_architecture.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
