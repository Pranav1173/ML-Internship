{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a6ffaf4-a79c-42e3-a122-cd019dd050dc",
   "metadata": {},
   "source": [
    "*Importing Dependencies*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0ae2689d-d7ae-4591-b98b-0b32a4461a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae3e5f2-d08d-448d-9f12-7a3cb726cd5e",
   "metadata": {},
   "source": [
    "*Here is the filename identifiers as per the official RAVDESS website: Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "Vocal channel (01 = speech, 02 = song).\n",
    "Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
    "Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
    "So, here's an example of an audio filename. 02-01-06-01-02-01-12.mp4 This means the meta data for the audio file is:* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f427fca-f8fc-419e-9a7b-8827c8fa2745",
   "metadata": {},
   "source": [
    "*Video-only (02) Speech (01) Fearful (06) Normal intensity (01) Statement \"dogs\" (02) 1st Repetition (01) 12th Actor (12) - Female (as the actor ID number is even)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "63890e3c-3142-4b56-89df-037c5144a227",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ravdess = \"audio_speech_actors_01-24\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "013e686e-c292-471f-9e87-fed96d2e4114",
   "metadata": {},
   "outputs": [],
   "source": [
    "ravdess_directory_list = os.listdir(Ravdess)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "for dir in ravdess_directory_list:\n",
    "    actor = os.listdir(Ravdess + '/' + dir)\n",
    "    for file in actor:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('-')\n",
    "        file_emotion.append(int(part[2]))\n",
    "        file_path.append(Ravdess + '/' + dir + '/' + file)\n",
    "        \n",
    "\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Ravdess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "\n",
    "Ravdess_df.Emotions.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)\n",
    "Ravdess_df.head()\n",
    "\n",
    "Ravdess_df.to_csv(\"data_path.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0191a2-dc2b-470b-b69e-f9924cea5aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1d757493-d9f1-46f4-afb8-801f08e0cd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_file_path, test_file_path):\n",
    "    train_data = pd.read_csv(train_file_path)\n",
    "    test_data = pd.read_csv(test_file_path)\n",
    "\n",
    "    X_train = np.array([preprocess_audio(audio_path) for audio_path in train_data['audio_file']])\n",
    "    y_train = train_data['emotion']\n",
    "\n",
    "    X_test = np.array([preprocess_audio(audio_path) for audio_path in test_data['audio_file']])\n",
    "    y_test = test_data['emotion']\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "91e7ae95-3af5-4c46-a4bc-596652c2066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(audio_path, max_len=11):\n",
    "    audio, _ = librosa.load(audio_path, res_type='kaiser_fast', duration=2.5, sr=22050*2, offset=0.5)\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=22050*2, n_mfcc=40)\n",
    "    pad_width = max_len - mfccs.shape[1]\n",
    "    mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447f68c5-50c4-40dc-b7f6-b8cbfa90f623",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = 'path/to/train/data.csv'\n",
    "test_file_path = 'path/to/test/data.csv'\n",
    "X_train, y_train, X_test, y_test = load_data(train_file_path, test_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
